{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "from transformers import AutoTokenizer,AutoModel\n",
    "from typing import List,Optional"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ChatGLM2(LLM):\n",
    "    max_token:int=4096  \n",
    "    temperature:float=0.8  # 让词语多样性更高\n",
    "    top_p=0.9       # 选择最大的概率之和小于0.9\n",
    "    tokenizer:object=None\n",
    "    model:object=None\n",
    "    history=[]\n",
    "    def __init_(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self)->str:\n",
    "        return \"ChatGLM2\"\n",
    "    \n",
    "    def load_model(self, model_path=None):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        self.model = AutoModel.from_pretrained(model_path, trust_remote_code=True).half().cuda()\n",
    "    \n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None):\n",
    "        response, history = self.model.chat(self.tokenizer, prompt, history=self.history, max_length=self.max_token, temperature=self.temperature, top_p=self.top_p)\n",
    "        \n",
    "        # 这里如何设置流式输出是个问题\n",
    "        \n",
    "        if stop is not None:\n",
    "            response = enforce_stop_tokens(response, stop)\n",
    "        self.history = self.history+[[None, response]]\n",
    "        return response\n",
    "    \n"
   ],
   "id": "60edf34720723135"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "545c3d5c6d6206a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
