自动微分模块

深度学习中最核心的就是设计模型，设计损失函数，更新参数。

更新参数时参数会根据损失函数关于对应参数的梯度更新。反向传播的作用是计算梯度。

pytorch内置了torch.autograd的微分引擎。它支持对任意计算图作自动计算梯度。



![image-20250630105431403](./assets/image-20250630105431403.png)

通过对计算图作backgrad（）方法来实现反向传播梯度计算，通过参数的grad方法来实现参数梯度的访问。